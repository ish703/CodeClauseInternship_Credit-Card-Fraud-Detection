# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eLs91pN8a12xEKf-kmHYRSV7iEQxVCzm
"""

# âœ… Step 1: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# âœ… Step 2: Load and Explore the Dataset
df = pd.read_csv('/creditcard.csv')  # Change this if using Google Colab upload

# View basic data info
print("ðŸ”¹ First 5 rows:")
print(df.head())

print("\nðŸ”¹ Dataset Info:")
print(df.info())

print("\nðŸ”¹ Statistical Summary:")
print(df.describe())

print("\nðŸ”¹ Class Distribution:")
print(df['Class'].value_counts())

# Optional: Plot class distribution
sns.countplot(x='Class', data=df)
plt.title("Class Distribution (0 = Non-Fraud, 1 = Fraud)")
plt.show()

# âœ… Step 3: Handle Imbalanced Dataset (Under-sampling)
fraud = df[df['Class'] == 1]
not_fraud = df[df['Class'] == 0].sample(n=len(fraud), random_state=42)

# Combine and shuffle
balanced_df = pd.concat([fraud, not_fraud]).sample(frac=1, random_state=42).reset_index(drop=True)

print("\nðŸ”¹ Balanced Class Counts:\n", balanced_df['Class'].value_counts())

# âœ… Step 4: Feature Scaling and Train-Test Split
X = balanced_df.drop(['Class', 'Time'], axis=1)
y = balanced_df['Class']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42)

print("ðŸ”¹ Training set size:", len(X_train))
print("ðŸ”¹ Test set size:", len(X_test))

# âœ… Step 5: Train and Evaluate the Model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluation
print("ðŸ”¹ Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nðŸ”¹ Classification Report:")
print(classification_report(y_test, y_pred))

print("ðŸ”¹ Accuracy Score:", accuracy_score(y_test, y_pred))
print("ðŸ”¹ ROC AUC Score:", roc_auc_score(y_test, y_pred))

# Optional: Confusion matrix heatmap
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()